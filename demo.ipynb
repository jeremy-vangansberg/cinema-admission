{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1743588008378
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: ./config.json\n",
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'./mlasset/'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import os\n",
        "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
        "\n",
        "\n",
        "# Connexion à Azure ML\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "# Récupération du data asset\n",
        "data_asset = ml_client.data.get(\"cinema_data_set\", version=\"3\")\n",
        "\n",
        "ASSET_NAME = \"cinema_data_set\"\n",
        "ASSET_VERSION = \"3\"\n",
        "LOCAL_PATH = \"./downloaded_data\"\n",
        "\n",
        "artifact_utils.download_artifact_from_aml_uri(uri = data_asset.path, destination = \"./mlasset/\", datastore_operation=ml_client.datastores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1743588013711
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mUploading titanic_data_cleaned.csv\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading titanic_data_cleaned.csv\u001b[32m (< 1 MB): 100%|██████████| 61.8k/61.8k [00:00<00:00, 4.85MB/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data({'path': 'azureml://subscriptions/72eb7803-e874-44cb-b6d9-33f2fa3eb88c/resourcegroups/jvangansbergrg/workspaces/myws/datastores/workspaceblobstore/paths/LocalUpload/336f33fafd464f8997bde01c3474f660/titanic_data_cleaned.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'titanic_data_set', 'description': 'Version nettoyée sans la colonne Cabin', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/72eb7803-e874-44cb-b6d9-33f2fa3eb88c/resourceGroups/jvangansbergrg/providers/Microsoft.MachineLearningServices/workspaces/myws/data/titanic_data_set/versions/2', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/testvmsimplon/code/Users/jvangansberg.ext/cinema-admission', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f41d47a47f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f41d47a4e50>, 'version': '2', 'latest_version': None, 'datastore': None})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "df_cleaned = df.drop(columns=[\"Cabin\"], errors=\"ignore\")\n",
        "\n",
        "# Sauvegarde locale du nouveau CSV\n",
        "cleaned_path = \"titanic_data_cleaned.csv\"\n",
        "df_cleaned.to_csv(cleaned_path, index=False)\n",
        "\n",
        "# Création de la nouvelle version du Data Asset (v2)\n",
        "new_data_asset = Data(\n",
        "    path=cleaned_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    name=\"titanic_data_set\",  # même nom\n",
        "    version=\"2\",              # nouvelle version\n",
        "    description=\"Version nettoyée sans la colonne Cabin\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(new_data_asset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1743588056326
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/mlflow/_protos/aml_service_pb2.py:10: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
            "  from google.protobuf import service as _service\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "2025/04/02 10:00:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Modèle loggé avec MLflow - F1: 0.759, Precision: 0.830, Recall: 0.698, AUC: 0.858\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Connexion + chargement du dataset v2\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "data_asset = ml_client.data.get(name=\"titanic_data_set\", version=\"2\")\n",
        "df = pd.read_csv(data_asset.path)\n",
        "\n",
        "# Préparation des données (exemple simple)\n",
        "df = df.dropna()\n",
        "X = df.drop(columns=[\"Survived\"])\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "# Dummy encoding si besoin (ex: pour les colonnes catégorielles)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Démarrer un run MLflow\n",
        "with mlflow.start_run():\n",
        "    model = LogisticRegression(max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Métriques\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    # Log avec MLflow\n",
        "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "\n",
        "    mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "    print(f\"✅ Modèle loggé avec MLflow - F1: {f1:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, AUC: {roc_auc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda list --explicit > environment.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
